#version: '3.8'

services:
  #  database:
  #    image: 'mysql:8.0'
  #    container_name: mysql-container
  #    env_file:
  #      - .env
  #    environment:
  #      MYSQL_ROOT_PASSWORD: ${DB_PASSWORD}
  #      MYSQL_DATABASE: portalsite
  #    ports:
  #      - "3307:3306"
  #    volumes:
  #      - mysql_data:/var/lib/mysql

  redis:
    image: redis:7.2
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://host.docker.internal:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # 웹 콘솔
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data

  elasticsearch:
    build:
      context: .
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - http.cors.enabled=true
      - http.cors.allow-origin="*"
      - http.cors.allow-methods=OPTIONS,HEAD,GET,POST,PUT,DELETE
      - http.cors.allow-headers=X-Requested-With,Content-Type,Content-Length,Authorization
      - network.host=0.0.0.0
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data

    command: >
      bash -c "if [ ! -f /usr/share/elasticsearch/plugins/analysis-nori/plugin-descriptor.properties ]; then
      elasticsearch-plugin install --batch analysis-nori; fi && /usr/local/bin/docker-entrypoint.sh"
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  kibana:
    image: 'kibana:8.15.1'
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

#  logstash:
#    build:
#      context: ./elasticsearch/logstash
#      dockerfile: Dockerfile
#    container_name: logstash
#    depends_on:
#      - kafka
#      - elasticsearch
#    volumes:
#      - ./elasticsearch/logstash/sync/pipeline:/usr/share/logstash/pipeline
#      - ./elasticsearch/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml


#  app:
#    build:
#      context: .
#      dockerfile: Dockerfile
#    container_name: portalsite
#    ports:
#      - "8080:8080"
#      - "5005:5005"
#    environment:
#      SPRING_DATASOURCE_URL: jdbc:mysql://database:3306/portalsite
#      SPRING_DATASOURCE_USERNAME: root
#      SPRING_DATASOURCE_PASSWORD: ${DB_PASSWORD}
#    depends_on:
#      - database
#      - redis
#    command: >
#      java
#      -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005
#      -jar /app/app.jar

volumes:
  mysql_data:
  minio_data:
  es_data: